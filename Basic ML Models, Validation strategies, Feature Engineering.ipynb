{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda:\n",
    "\n",
    "- Basic data cleaning - One Hot Encoding, Feature Scaling\n",
    "- Train - test split\n",
    "- Distance-based Models (kNN)\n",
    "- Accuracy Metrics\n",
    "- Validation Strategies (Validation Set)\n",
    "- Cross - Validation\n",
    "- Linear Models (Linear Regression/**Logistic Regression**)\n",
    "- Model improvement stratgies: Impact of Feature Engineering/Feature Selection, missing value imputation, cleaning/capping outliers, balancing target categories (oversampling/SMOTE) \n",
    "- Tree-based models (if time permits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement:\n",
    "\n",
    "ABC Bank has provided us with a dataset that contains customer details for their customers in `BankAttrition - Details.csv` file. The transactions related information and what kind of credit card the customer holds is provided to us in another file `Transaction and Card Details.csv`. The bank is currently facing problems of customer attrition. They have consulted us to understand how can they understand the patterns of customer attrition and if they can get early signals so to stop losing customers.\n",
    "\n",
    "Till now: Merged data, performed exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10127, 8), (10127, 14))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read input files\n",
    "details = pd.read_csv(\"Datasets/BankAttrition - Details.csv\")\n",
    "transaction = pd.read_csv(\"Datasets/Transaction and Card Details.csv\")\n",
    "\n",
    "details.shape, transaction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to create ADS\n",
    "\n",
    "ads = pd.merge(details, transaction, how = 'outer', on = ['CLIENTNUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10127 entries, 0 to 10126\n",
      "Data columns (total 21 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   CLIENTNUM                 10127 non-null  int64  \n",
      " 1   Attrition_Flag            10127 non-null  object \n",
      " 2   Customer_Age              10127 non-null  int64  \n",
      " 3   Gender                    10127 non-null  object \n",
      " 4   Dependent_count           10127 non-null  int64  \n",
      " 5   Education_Level           10127 non-null  object \n",
      " 6   Marital_Status            10127 non-null  object \n",
      " 7   Income_Category           10127 non-null  object \n",
      " 8   Card_Category             10127 non-null  object \n",
      " 9   Months_on_book            10127 non-null  int64  \n",
      " 10  Total_Relationship_Count  10127 non-null  int64  \n",
      " 11  Months_Inactive_12_mon    10127 non-null  int64  \n",
      " 12  Contacts_Count_12_mon     10127 non-null  int64  \n",
      " 13  Credit_Limit              10127 non-null  float64\n",
      " 14  Total_Revolving_Bal       10127 non-null  int64  \n",
      " 15  Avg_Open_To_Buy           10127 non-null  float64\n",
      " 16  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n",
      " 17  Total_Trans_Amt           10127 non-null  int64  \n",
      " 18  Total_Trans_Ct            10127 non-null  int64  \n",
      " 19  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n",
      " 20  Avg_Utilization_Ratio     10127 non-null  float64\n",
      "dtypes: float64(5), int64(10), object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "ads.info()\n",
    "\n",
    "## consider Unknown as a separate category\n",
    "# typecasting variables\n",
    "ads['Gender'] = ads['Gender'].astype('category')\n",
    "ads['Education_Level'] = ads['Education_Level'].astype('category')\n",
    "ads['Marital_Status'] = ads['Marital_Status'].astype('category')\n",
    "ads['Income_Category'] = ads['Income_Category'].astype('category')\n",
    "ads['Card_Category'] = ads['Card_Category'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ClientNum as it is just the identifier\n",
    "ads.drop([\"CLIENTNUM\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High School', 'Graduate', 'Uneducated', 'Unknown', 'College', 'Post-Graduate', 'Doctorate']\n",
       "Categories (7, object): ['High School', 'Graduate', 'Uneducated', 'Unknown', 'College', 'Post-Graduate', 'Doctorate']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads['Education_Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ed = {\n",
    "    \"Unknown\": -1,\n",
    "    \"Uneducated\": 0,\n",
    "    \"High School\": 1,\n",
    "    \"College\": 2,\n",
    "    \"Graduate\": 2,\n",
    "    \"Post-Graduate\": 3,\n",
    "    \"Doctorate\": 4\n",
    "}\n",
    "\n",
    "ads[\"Education_Level\"] = ads[\"Education_Level\"].map(labels_ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Less than $40K    0.351634\n",
       "$40K - $60K       0.176755\n",
       "$80K - $120K      0.151575\n",
       "$60K - $80K       0.138442\n",
       "Unknown           0.109805\n",
       "$120K +           0.071788\n",
       "Name: Income_Category, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads['Income_Category'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_income = {\n",
    "    \"Unknown\": 0.11,\n",
    "    'Less than $40K': 0.35,\n",
    "    '$40K - $60K': 0.17,\n",
    "    '$60K - $80K': 0.14,\n",
    "    '$80K - $120K': 0.15,\n",
    "    '$120K +': 0.07\n",
    "}\n",
    "\n",
    "ads[\"Income_Category\"] = ads[\"Income_Category\"].map(labels_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.14</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.15</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.14</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.17</td>\n",
       "      <td>Blue</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1851</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>15476</td>\n",
       "      <td>117</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.17</td>\n",
       "      <td>Blue</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>2186</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>0.804</td>\n",
       "      <td>8764</td>\n",
       "      <td>69</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0.819</td>\n",
       "      <td>10291</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.17</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>8395</td>\n",
       "      <td>62</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Silver</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10388.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>8427.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10294</td>\n",
       "      <td>61</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0      Existing Customer            45      M                3   \n",
       "1      Existing Customer            49      F                5   \n",
       "2      Existing Customer            51      M                3   \n",
       "3      Existing Customer            40      F                4   \n",
       "4      Existing Customer            40      M                3   \n",
       "...                  ...           ...    ...              ...   \n",
       "10122  Existing Customer            50      M                2   \n",
       "10123  Attrited Customer            41      M                2   \n",
       "10124  Attrited Customer            44      F                1   \n",
       "10125  Attrited Customer            30      M                2   \n",
       "10126  Attrited Customer            43      F                2   \n",
       "\n",
       "       Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0                    1        Married            0.14          Blue   \n",
       "1                    2         Single            0.35          Blue   \n",
       "2                    2        Married            0.15          Blue   \n",
       "3                    1        Unknown            0.35          Blue   \n",
       "4                    0        Married            0.14          Blue   \n",
       "...                ...            ...             ...           ...   \n",
       "10122                2         Single            0.17          Blue   \n",
       "10123               -1       Divorced            0.17          Blue   \n",
       "10124                1        Married            0.35          Blue   \n",
       "10125                2        Unknown            0.17          Blue   \n",
       "10126                2        Married            0.35        Silver   \n",
       "\n",
       "       Months_on_book  Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0                  39                         5                       1   \n",
       "1                  44                         6                       1   \n",
       "2                  36                         4                       1   \n",
       "3                  34                         3                       4   \n",
       "4                  21                         5                       1   \n",
       "...               ...                       ...                     ...   \n",
       "10122              40                         3                       2   \n",
       "10123              25                         4                       2   \n",
       "10124              36                         5                       3   \n",
       "10125              36                         4                       3   \n",
       "10126              25                         6                       2   \n",
       "\n",
       "       Contacts_Count_12_mon  Credit_Limit  Total_Revolving_Bal  \\\n",
       "0                          3       12691.0                  777   \n",
       "1                          2        8256.0                  864   \n",
       "2                          0        3418.0                    0   \n",
       "3                          1        3313.0                 2517   \n",
       "4                          0        4716.0                    0   \n",
       "...                      ...           ...                  ...   \n",
       "10122                      3        4003.0                 1851   \n",
       "10123                      3        4277.0                 2186   \n",
       "10124                      4        5409.0                    0   \n",
       "10125                      3        5281.0                    0   \n",
       "10126                      4       10388.0                 1961   \n",
       "\n",
       "       Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "0              11914.0                 1.335             1144              42   \n",
       "1               7392.0                 1.541             1291              33   \n",
       "2               3418.0                 2.594             1887              20   \n",
       "3                796.0                 1.405             1171              20   \n",
       "4               4716.0                 2.175              816              28   \n",
       "...                ...                   ...              ...             ...   \n",
       "10122           2152.0                 0.703            15476             117   \n",
       "10123           2091.0                 0.804             8764              69   \n",
       "10124           5409.0                 0.819            10291              60   \n",
       "10125           5281.0                 0.535             8395              62   \n",
       "10126           8427.0                 0.703            10294              61   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0                    1.625                  0.061  \n",
       "1                    3.714                  0.105  \n",
       "2                    2.333                  0.000  \n",
       "3                    2.333                  0.760  \n",
       "4                    2.500                  0.000  \n",
       "...                    ...                    ...  \n",
       "10122                0.857                  0.462  \n",
       "10123                0.683                  0.511  \n",
       "10124                0.818                  0.000  \n",
       "10125                0.722                  0.000  \n",
       "10126                0.649                  0.189  \n",
       "\n",
       "[10127 rows x 20 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the categories\n",
    "categorical_vars = ads.select_dtypes(include = ['category']).columns\n",
    "\n",
    "ads = pd.get_dummies(ads, columns = categorical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>...</th>\n",
       "      <th>Income_Category_0.07</th>\n",
       "      <th>Income_Category_0.17</th>\n",
       "      <th>Income_Category_0.14</th>\n",
       "      <th>Income_Category_0.15</th>\n",
       "      <th>Income_Category_0.35</th>\n",
       "      <th>Income_Category_0.11</th>\n",
       "      <th>Card_Category_Blue</th>\n",
       "      <th>Card_Category_Gold</th>\n",
       "      <th>Card_Category_Platinum</th>\n",
       "      <th>Card_Category_Silver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1851</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>2186</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10388.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Attrition_Flag  Customer_Age  Dependent_count  Education_Level  \\\n",
       "0      Existing Customer            45                3                1   \n",
       "1      Existing Customer            49                5                2   \n",
       "2      Existing Customer            51                3                2   \n",
       "3      Existing Customer            40                4                1   \n",
       "4      Existing Customer            40                3                0   \n",
       "...                  ...           ...              ...              ...   \n",
       "10122  Existing Customer            50                2                2   \n",
       "10123  Attrited Customer            41                2               -1   \n",
       "10124  Attrited Customer            44                1                1   \n",
       "10125  Attrited Customer            30                2                2   \n",
       "10126  Attrited Customer            43                2                2   \n",
       "\n",
       "       Months_on_book  Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0                  39                         5                       1   \n",
       "1                  44                         6                       1   \n",
       "2                  36                         4                       1   \n",
       "3                  34                         3                       4   \n",
       "4                  21                         5                       1   \n",
       "...               ...                       ...                     ...   \n",
       "10122              40                         3                       2   \n",
       "10123              25                         4                       2   \n",
       "10124              36                         5                       3   \n",
       "10125              36                         4                       3   \n",
       "10126              25                         6                       2   \n",
       "\n",
       "       Contacts_Count_12_mon  Credit_Limit  Total_Revolving_Bal  ...  \\\n",
       "0                          3       12691.0                  777  ...   \n",
       "1                          2        8256.0                  864  ...   \n",
       "2                          0        3418.0                    0  ...   \n",
       "3                          1        3313.0                 2517  ...   \n",
       "4                          0        4716.0                    0  ...   \n",
       "...                      ...           ...                  ...  ...   \n",
       "10122                      3        4003.0                 1851  ...   \n",
       "10123                      3        4277.0                 2186  ...   \n",
       "10124                      4        5409.0                    0  ...   \n",
       "10125                      3        5281.0                    0  ...   \n",
       "10126                      4       10388.0                 1961  ...   \n",
       "\n",
       "       Income_Category_0.07  Income_Category_0.17  Income_Category_0.14  \\\n",
       "0                         0                     0                     1   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     1   \n",
       "...                     ...                   ...                   ...   \n",
       "10122                     0                     1                     0   \n",
       "10123                     0                     1                     0   \n",
       "10124                     0                     0                     0   \n",
       "10125                     0                     1                     0   \n",
       "10126                     0                     0                     0   \n",
       "\n",
       "       Income_Category_0.15  Income_Category_0.35  Income_Category_0.11  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     1                     0   \n",
       "2                         1                     0                     0   \n",
       "3                         0                     1                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "10122                     0                     0                     0   \n",
       "10123                     0                     0                     0   \n",
       "10124                     0                     1                     0   \n",
       "10125                     0                     0                     0   \n",
       "10126                     0                     1                     0   \n",
       "\n",
       "       Card_Category_Blue  Card_Category_Gold  Card_Category_Platinum  \\\n",
       "0                       1                   0                       0   \n",
       "1                       1                   0                       0   \n",
       "2                       1                   0                       0   \n",
       "3                       1                   0                       0   \n",
       "4                       1                   0                       0   \n",
       "...                   ...                 ...                     ...   \n",
       "10122                   1                   0                       0   \n",
       "10123                   1                   0                       0   \n",
       "10124                   1                   0                       0   \n",
       "10125                   1                   0                       0   \n",
       "10126                   0                   0                       0   \n",
       "\n",
       "       Card_Category_Silver  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "...                     ...  \n",
       "10122                     0  \n",
       "10123                     0  \n",
       "10124                     0  \n",
       "10125                     0  \n",
       "10126                     1  \n",
       "\n",
       "[10127 rows x 32 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Attrition_Flag', 'Customer_Age', 'Dependent_count', 'Education_Level',\n",
       "       'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
       "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
       "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
       "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio',\n",
       "       'Gender_F', 'Gender_M', 'Marital_Status_Divorced',\n",
       "       'Marital_Status_Married', 'Marital_Status_Single',\n",
       "       'Marital_Status_Unknown', 'Income_Category_0.07',\n",
       "       'Income_Category_0.17', 'Income_Category_0.14', 'Income_Category_0.15',\n",
       "       'Income_Category_0.35', 'Income_Category_0.11', 'Card_Category_Blue',\n",
       "       'Card_Category_Gold', 'Card_Category_Platinum', 'Card_Category_Silver'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-1fff1c3e04b1>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ads['Attrition_Flag'][ads['Attrition_Flag'] == 'Existing Customer'] = 0\n",
      "<ipython-input-61-1fff1c3e04b1>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ads['Attrition_Flag'][ads['Attrition_Flag'] == 'Attrited Customer'] = 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# encoding target to - 0, 1\n",
    "ads['Attrition_Flag'][ads['Attrition_Flag'] == 'Existing Customer'] = 0\n",
    "ads['Attrition_Flag'][ads['Attrition_Flag'] == 'Attrited Customer'] = 1\n",
    "ads['Attrition_Flag'] = ads['Attrition_Flag'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineer\n",
    "ads['Credit_Limit'] = np.log(ads['Credit_Limit'])\n",
    "ads['Total_Revolving_Bal'] = np.log(ads['Total_Revolving_Bal'] + 0.01)\n",
    "ads['Total_Trans_Amt'] = np.log(ads['Total_Trans_Amt'] + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-2bd76680991b>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ads['book_cat'][(ads['Months_on_book']<= 20)]='Low'\n",
      "<ipython-input-63-2bd76680991b>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ads['book_cat'][(ads['Months_on_book'] > 20)] = 'Medium'\n",
      "<ipython-input-63-2bd76680991b>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ads['book_cat'][(ads['Months_on_book']> 50)] = 'High'\n",
      "<ipython-input-63-2bd76680991b>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ads['open_buy_cat'][(ads['Avg_Utilization_Ratio']<= 0)]='Low'\n",
      "<ipython-input-63-2bd76680991b>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ads['open_buy_cat'][(ads['Avg_Utilization_Ratio'] > 0) & (ads['Avg_Utilization_Ratio']<= 0.7)] = 'Medium'\n",
      "<ipython-input-63-2bd76680991b>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ads['open_buy_cat'][ads['Avg_Utilization_Ratio']> 0.7] = 'High'\n"
     ]
    }
   ],
   "source": [
    "bins = [0, 18, 30, 50, 70, 200]\n",
    "ads['binned_age'] = pd.cut(ads['Customer_Age'], bins)\n",
    "\n",
    "\n",
    "ads['book_cat'] = None\n",
    "ads['book_cat'][(ads['Months_on_book']<= 20)]='Low'\n",
    "ads['book_cat'][(ads['Months_on_book'] > 20)] = 'Medium'\n",
    "ads['book_cat'][(ads['Months_on_book']> 50)] = 'High'\n",
    "ads['book_cat'] = ads['book_cat'].astype('category')\n",
    "\n",
    "\n",
    "ads['open_buy_cat'] = None\n",
    "ads['open_buy_cat'][(ads['Avg_Utilization_Ratio']<= 0)]='Low'\n",
    "ads['open_buy_cat'][(ads['Avg_Utilization_Ratio'] > 0) & (ads['Avg_Utilization_Ratio']<= 0.7)] = 'Medium'\n",
    "ads['open_buy_cat'][ads['Avg_Utilization_Ratio']> 0.7] = 'High'\n",
    "ads['open_buy_cat'] = ads['open_buy_cat'].astype('category')\n",
    "\n",
    "ads = pd.get_dummies(ads, columns = ['binned_age', 'book_cat', 'open_buy_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10127, 42), (10127,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seperating independent and dependent variables\n",
    "x = ads.drop(['Attrition_Flag'], axis=1)\n",
    "y = ads['Attrition_Flag']\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.83934\n",
       "1    0.16066\n",
       "Name: Attrition_Flag, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    6375\n",
       " 0    6375\n",
       " Name: Attrition_Flag, dtype: int64,\n",
       " 0    2125\n",
       " 1     407\n",
       " Name: Attrition_Flag, dtype: int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the train test split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, random_state =123, stratify = y, test_size = 0.25)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(k_neighbors = 4)\n",
    "\n",
    "x_smote, y_smote = smote.fit_resample(train_x, train_y)\n",
    "\n",
    "y_smote.value_counts(), test_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0.839368\n",
       " 1    0.160632\n",
       " Name: Attrition_Flag, dtype: float64,\n",
       " 0    0.839258\n",
       " 1    0.160742\n",
       " Name: Attrition_Flag, dtype: float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts(normalize = True), test_y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scalers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick knn model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "clf = KNN(n_neighbors = 7)\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = clf.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = clf.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_curve(k):\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    \n",
    "    for i in k:\n",
    "        clf = KNN(n_neighbors = i, metric = \"manhattan\")\n",
    "        clf.fit(x_smote, y_smote)\n",
    "        \n",
    "        train_yhat = clf.predict(train_x)\n",
    "        train_score_tmp = f1_score(train_y, train_yhat)\n",
    "        train_score.append(train_score_tmp)\n",
    "        \n",
    "        test_yhat = clf.predict(test_x)\n",
    "        test_score_tmp = f1_score(test_y, test_yhat)\n",
    "        test_score.append(test_score_tmp)\n",
    "        \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = range(1, 30, 2)\n",
    "\n",
    "train_f1, test_f1 = elbow_curve(k)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(k, train_f1, label = \"train_f1\", color = \"red\")\n",
    "plt.plot(k, test_f1, label = \"test_f1\", color = \"black\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "lr = LR(max_iter = 10000, penalty = \"l1\", solver = 'saga')\n",
    "lr.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = lr.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = lr.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "sfs1 = sfs(lr,\n",
    "          k_features = 20,\n",
    "          forward = True,\n",
    "          scoring = 'f1',\n",
    "          cv = 3)\n",
    "\n",
    "sfs1 = sfs1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected = list(sfs1.k_feature_idx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR(max_iter = 10000)\n",
    "lr.fit(train_x[:, features_selected], train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = lr.predict(train_x[:, features_selected])\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = lr.predict(test_x[:, features_selected])\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.863013698630137, 0.8312655086848636)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "dt_model = DT(random_state = 555, max_depth = 6)\n",
    "dt_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = dt_model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = dt_model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuning a DT on depth\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "for depth in range(1, 30):\n",
    "    dt_model = DT(random_state = 555, max_depth = depth)\n",
    "    dt_model.fit(train_x, train_y)\n",
    "    train_yhat = dt_model.predict(train_x)\n",
    "    train_f1 = f1_score(train_y, train_yhat)\n",
    "    train_score.append(train_f1)\n",
    "    test_yhat = dt_model.predict(test_x)\n",
    "    test_f1 = f1_score(test_y, test_yhat)\n",
    "    test_score.append(test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'max_depth': range(1, 30), 'train_score': train_score, 'test_score': test_score})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['max_depth'], df['train_score'], marker = 'o')\n",
    "plt.plot(df['max_depth'], df['test_score'], marker = 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=555),\n",
       "                   n_iter=300,\n",
       "                   param_distributions={'ccp_alpha': [0, 0.01, 0.1, 1],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [6, 10, 15],\n",
       "                                        'max_leaf_nodes': [2, 7, 12, 17, 22, 27,\n",
       "                                                           32, 37, 42, 47],\n",
       "                                        'min_samples_split': [2, 7, 12, 17, 22,\n",
       "                                                              27, 32, 37, 42,\n",
       "                                                              47]},\n",
       "                   scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search CV - Model Tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'max_depth': [6, 10, 15], 'min_samples_split': list(range(2, 50, 5)), 'criterion': ['gini', 'entropy'],\n",
    "         'max_leaf_nodes': list(range(2, 50, 5)), 'ccp_alpha': [0, 0.01, 0.1, 1]}\n",
    "\n",
    "grid_search = RandomizedSearchCV(DecisionTreeClassifier(random_state = 555), param_distributions = params, scoring = 'f1', cv = 3, \n",
    "                           verbose = 1, n_iter = 300)\n",
    "grid_search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0, max_depth=15, max_leaf_nodes=42,\n",
       "                       min_samples_split=7, random_state=555)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8548179871520343, 0.8300492610837438)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "dt_model = DT(ccp_alpha=0, max_depth=6, max_leaf_nodes=42,\n",
    "                       min_samples_split=7, random_state=555)\n",
    "\n",
    "dt_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = dt_model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = dt_model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8423772609819121)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "rf_model = RF(random_state = 555)\n",
    "rf_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = rf_model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = rf_model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=555),\n",
       "                   n_iter=200,\n",
       "                   param_distributions={'ccp_alpha': [0, 0.01, 0.1, 1],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [5, 10, 15],\n",
       "                                        'max_leaf_nodes': [2, 7, 12, 17, 22, 27,\n",
       "                                                           32, 37, 42, 47],\n",
       "                                        'min_samples_split': [2, 7, 12, 17, 22,\n",
       "                                                              27, 32, 37, 42,\n",
       "                                                              47],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "params = {'max_depth': [5, 10, 15], 'min_samples_split': list(range(2, 50, 5)), 'criterion': ['gini', 'entropy'],\n",
    "         'max_leaf_nodes': list(range(2, 50, 5)), 'ccp_alpha': [0, 0.01, 0.1, 1], 'n_estimators': [100, 200, 300, 400, 500]}\n",
    "\n",
    "grid_search = RandomizedSearchCV(RF(random_state = 555), param_distributions = params, scoring = 'f1', cv = 3, \n",
    "                           verbose = 1, n_iter = 200)\n",
    "grid_search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(ccp_alpha=0, criterion='entropy', max_depth=15,\n",
       "                       max_leaf_nodes=47, min_samples_split=22,\n",
       "                       n_estimators=300, random_state=555)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7731660231660231, 0.7402031930333817)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "rf_model = RF(ccp_alpha=0, criterion='entropy', max_depth=15,\n",
    "                       max_leaf_nodes=47, min_samples_split=22,\n",
    "                       n_estimators=300, random_state=555)\n",
    "rf_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = rf_model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = rf_model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9224211423699915, 0.8854568854568855)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBM\n",
    "\n",
    "gbm_model = GBM(random_state = 555)\n",
    "gbm_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = gbm_model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = gbm_model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END ccp_alpha=1, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.000 total time=  12.5s\n",
      "[CV 2/3] END ccp_alpha=1, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.000 total time=  13.9s\n",
      "[CV 3/3] END ccp_alpha=1, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.000 total time=  12.3s\n",
      "[CV 1/3] END ccp_alpha=0, learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.901 total time=   9.6s\n",
      "[CV 2/3] END ccp_alpha=0, learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.899 total time=  10.3s\n",
      "[CV 3/3] END ccp_alpha=0, learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.884 total time=  11.3s\n",
      "[CV 1/3] END ccp_alpha=0.01, learning_rate=0.3, max_depth=7, n_estimators=100;, score=0.512 total time=   4.4s\n",
      "[CV 2/3] END ccp_alpha=0.01, learning_rate=0.3, max_depth=7, n_estimators=100;, score=0.383 total time=   4.5s\n",
      "[CV 3/3] END ccp_alpha=0.01, learning_rate=0.3, max_depth=7, n_estimators=100;, score=0.487 total time=   4.5s\n",
      "[CV 1/3] END ccp_alpha=0.1, learning_rate=0.1, max_depth=2, n_estimators=500;, score=0.000 total time=   6.9s\n",
      "[CV 2/3] END ccp_alpha=0.1, learning_rate=0.1, max_depth=2, n_estimators=500;, score=0.000 total time=   7.2s\n",
      "[CV 3/3] END ccp_alpha=0.1, learning_rate=0.1, max_depth=2, n_estimators=500;, score=0.000 total time=   7.9s\n",
      "[CV 1/3] END ccp_alpha=0.1, learning_rate=0.5, max_depth=7, n_estimators=100;, score=0.000 total time=   6.0s\n",
      "[CV 2/3] END ccp_alpha=0.1, learning_rate=0.5, max_depth=7, n_estimators=100;, score=0.000 total time=   4.3s\n",
      "[CV 3/3] END ccp_alpha=0.1, learning_rate=0.5, max_depth=7, n_estimators=100;, score=0.000 total time=   4.8s\n",
      "[CV 1/3] END ccp_alpha=0.01, learning_rate=0.05, max_depth=3, n_estimators=400;, score=0.000 total time=   8.3s\n",
      "[CV 2/3] END ccp_alpha=0.01, learning_rate=0.05, max_depth=3, n_estimators=400;, score=0.000 total time=   8.2s\n",
      "[CV 3/3] END ccp_alpha=0.01, learning_rate=0.05, max_depth=3, n_estimators=400;, score=0.000 total time=   8.1s\n",
      "[CV 1/3] END ccp_alpha=1, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.000 total time=  22.7s\n",
      "[CV 2/3] END ccp_alpha=1, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.000 total time=  23.5s\n",
      "[CV 3/3] END ccp_alpha=1, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.000 total time=  22.0s\n",
      "[CV 1/3] END ccp_alpha=1, learning_rate=0.2, max_depth=7, n_estimators=400;, score=0.000 total time=  18.4s\n",
      "[CV 2/3] END ccp_alpha=1, learning_rate=0.2, max_depth=7, n_estimators=400;, score=0.000 total time=  17.6s\n",
      "[CV 3/3] END ccp_alpha=1, learning_rate=0.2, max_depth=7, n_estimators=400;, score=0.000 total time=  18.6s\n",
      "[CV 1/3] END ccp_alpha=1, learning_rate=0.1, max_depth=2, n_estimators=300;, score=0.000 total time=   4.2s\n",
      "[CV 2/3] END ccp_alpha=1, learning_rate=0.1, max_depth=2, n_estimators=300;, score=0.000 total time=   4.8s\n",
      "[CV 3/3] END ccp_alpha=1, learning_rate=0.1, max_depth=2, n_estimators=300;, score=0.000 total time=   4.2s\n",
      "[CV 1/3] END ccp_alpha=0.01, learning_rate=0.5, max_depth=7, n_estimators=100;, score=0.593 total time=   4.5s\n",
      "[CV 2/3] END ccp_alpha=0.01, learning_rate=0.5, max_depth=7, n_estimators=100;, score=0.589 total time=   4.4s\n",
      "[CV 3/3] END ccp_alpha=0.01, learning_rate=0.5, max_depth=7, n_estimators=100;, score=0.595 total time=   4.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=555),\n",
       "                   param_distributions={'ccp_alpha': [0, 0.01, 0.1, 1],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.2, 0.3,\n",
       "                                                          0.5],\n",
       "                                        'max_depth': [2, 3, 5, 7],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "params = {'max_depth': [2, 3, 5, 7], \n",
    "          'learning_rate': [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "          'ccp_alpha': [0, 0.01, 0.1, 1], 'n_estimators': [100, 200, 300, 400, 500]}\n",
    "\n",
    "grid_search = RandomizedSearchCV(GBM(random_state = 555), param_distributions = params, scoring = 'f1', cv = 3, \n",
    "                           verbose = 3, n_iter = 10)\n",
    "grid_search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0, max_depth=7, n_estimators=200,\n",
       "                           random_state=555)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9987689782519491, 0.9016602809706258)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBM\n",
    "\n",
    "gbm_model = GBM(ccp_alpha=0, max_depth=5, n_estimators=200,\n",
    "                           random_state=555)\n",
    "gbm_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = gbm_model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = gbm_model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.910691823899371)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[16:30:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.3, max_depth=10, n_estimators=100;, score=0.883 total time=   1.4s\n",
      "[16:30:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.3, max_depth=10, n_estimators=100;, score=0.902 total time=   2.1s\n",
      "[16:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.3, max_depth=10, n_estimators=100;, score=0.904 total time=   2.9s\n",
      "[16:30:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.5, max_depth=10, n_estimators=400;, score=0.880 total time=   7.7s\n",
      "[16:30:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.5, max_depth=10, n_estimators=400;, score=0.904 total time=   6.5s\n",
      "[16:31:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.5, max_depth=10, n_estimators=400;, score=0.908 total time=   3.8s\n",
      "[16:31:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.3, max_depth=5, n_estimators=100;, score=0.892 total time=   1.8s\n",
      "[16:31:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.3, max_depth=5, n_estimators=100;, score=0.917 total time=   1.8s\n",
      "[16:31:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.3, max_depth=5, n_estimators=100;, score=0.901 total time=   1.4s\n",
      "[16:31:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.881 total time=   0.9s\n",
      "[16:31:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.883 total time=   0.7s\n",
      "[16:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.879 total time=   0.8s\n",
      "[16:31:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=100;, score=0.867 total time=   1.1s\n",
      "[16:31:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=100;, score=0.875 total time=   1.9s\n",
      "[16:31:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=100;, score=0.876 total time=   1.5s\n",
      "[16:31:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.2, max_depth=2, n_estimators=400;, score=0.901 total time=   2.4s\n",
      "[16:31:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.2, max_depth=2, n_estimators=400;, score=0.904 total time=   1.9s\n",
      "[16:31:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.2, max_depth=2, n_estimators=400;, score=0.905 total time=   3.6s\n",
      "[16:31:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.889 total time=   4.9s\n",
      "[16:31:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.904 total time=   3.6s\n",
      "[16:31:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.898 total time=   5.0s\n",
      "[16:31:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.05, max_depth=2, n_estimators=300;, score=0.879 total time=   1.9s\n",
      "[16:31:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.05, max_depth=2, n_estimators=300;, score=0.855 total time=   2.2s\n",
      "[16:31:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.05, max_depth=2, n_estimators=300;, score=0.863 total time=   1.7s\n",
      "[16:31:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.2, max_depth=7, n_estimators=400;, score=0.894 total time=   5.1s\n",
      "[16:31:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.2, max_depth=7, n_estimators=400;, score=0.905 total time=   4.7s\n",
      "[16:31:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.2, max_depth=7, n_estimators=400;, score=0.898 total time=   5.0s\n",
      "[16:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.903 total time=   2.5s\n",
      "[16:32:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.913 total time=   2.4s\n",
      "[16:32:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.894 total time=   2.8s\n",
      "[16:32:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.3, max_depth=2, n_estimators=400;, score=0.897 total time=   2.2s\n",
      "[16:32:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.3, max_depth=2, n_estimators=400;, score=0.898 total time=   2.1s\n",
      "[16:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.3, max_depth=2, n_estimators=400;, score=0.899 total time=   1.9s\n",
      "[16:32:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.3, max_depth=7, n_estimators=400;, score=0.884 total time=   7.3s\n",
      "[16:32:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.3, max_depth=7, n_estimators=400;, score=0.897 total time=   5.7s\n",
      "[16:32:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.3, max_depth=7, n_estimators=400;, score=0.898 total time=   4.3s\n",
      "[16:32:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=400;, score=0.894 total time=   5.4s\n",
      "[16:32:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=400;, score=0.904 total time=   6.6s\n",
      "[16:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=400;, score=0.898 total time=   8.2s\n",
      "[16:32:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.2, max_depth=2, n_estimators=100;, score=0.901 total time=   0.6s\n",
      "[16:32:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.2, max_depth=2, n_estimators=100;, score=0.880 total time=   0.6s\n",
      "[16:32:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.2, max_depth=2, n_estimators=100;, score=0.877 total time=   0.6s\n",
      "[16:32:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=400;, score=0.890 total time=   4.5s\n",
      "[16:33:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=400;, score=0.908 total time=   3.7s\n",
      "[16:33:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=400;, score=0.905 total time=   4.0s\n",
      "[16:33:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.897 total time=   7.2s\n",
      "[16:33:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.908 total time=   7.2s\n",
      "[16:33:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.900 total time=   7.5s\n",
      "[16:33:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.3, max_depth=7, n_estimators=100;, score=0.887 total time=   1.1s\n",
      "[16:33:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.3, max_depth=7, n_estimators=100;, score=0.896 total time=   1.5s\n",
      "[16:33:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.3, max_depth=7, n_estimators=100;, score=0.892 total time=   1.5s\n",
      "[16:33:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.896 total time=   3.2s\n",
      "[16:33:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.900 total time=   3.1s\n",
      "[16:33:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.901 total time=   3.4s\n",
      "[16:33:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.885 total time=   5.0s\n",
      "[16:33:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.898 total time=   5.0s\n",
      "[16:33:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.904 total time=   5.5s\n",
      "[16:34:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=500;, score=0.891 total time=   5.7s\n",
      "[16:34:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=500;, score=0.912 total time=   5.7s\n",
      "[16:34:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=500;, score=0.909 total time=   6.0s\n",
      "[16:34:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=500, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "params = {'max_depth': [2, 3, 5, 7, 10], \n",
    "          'learning_rate': [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "          'n_estimators': [100, 200, 300, 400, 500]\n",
    "         }\n",
    "\n",
    "grid_search = RandomizedSearchCV(model, param_distributions = params, scoring = 'f1', cv = 3, \n",
    "                           verbose = 3, n_iter = 20)\n",
    "grid_search.fit(train_x, train_y)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:36:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9959049959049959, 0.9147869674185464)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=500, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logitboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting logitboost\n",
      "  Downloading logitboost-0.7-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\prashant\\anaconda3\\lib\\site-packages (from logitboost) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\prashant\\anaconda3\\lib\\site-packages (from logitboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\prashant\\anaconda3\\lib\\site-packages (from logitboost) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prashant\\anaconda3\\lib\\site-packages (from scikit-learn->logitboost) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\prashant\\anaconda3\\lib\\site-packages (from scikit-learn->logitboost) (0.17.0)\n",
      "Installing collected packages: logitboost\n",
      "Successfully installed logitboost-0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install logitboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9247491638795986, 0.8849557522123894)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from logitboost import LogitBoost\n",
    "\n",
    "lboost = LogitBoost(n_estimators = 200, random_state = 555)\n",
    "lboost.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = lboost.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = lboost.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9835661462612982, 0.8936708860759494)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators = 500, random_state = 555)),\n",
    "             ('lb', LogitBoost(n_estimators = 200, random_state = 555))\n",
    "             ]\n",
    "\n",
    "clf = StackingClassifier(estimators)\n",
    "\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = clf.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = clf.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7735849056603773, 0.7091172214182345)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(train_x, train_y)\n",
    "\n",
    "# make training prediction\n",
    "train_yhat = svc_model.predict(train_x)\n",
    "train_score = f1_score(train_y, train_yhat)\n",
    "\n",
    "# make test prediction\n",
    "test_yhat = svc_model.predict(test_x)\n",
    "test_score = f1_score(test_y, test_yhat)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuning SVM takes a lot of time\n",
    "\n",
    "param_dist = {\"C\":[0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "             \"kernel\": ['linear', 'poly', 'rbf'],\n",
    "             \"degree\": [2, 3, 4],\n",
    "             \"gamma\": ['auto', 'scale']}\n",
    "\n",
    "grid_search = RandomizedSearchCV(svc_model, param_dist, cv = 3, n_iter = 30,  \n",
    "                                   verbose=10, n_jobs=-1, scoring = \"f1\")\n",
    "\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
